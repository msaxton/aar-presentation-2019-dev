---
layout: page
title: Argument
---

# Argument



### Intro

Unease about artificial intelligence is often expressed in terms of the effects of bias,  or job displacement, or singularity (the fear that AI will take over). Our thesis is that a major source of uneasiness, one which has not been much explored, is AI's uncanniness.

In the mid-late Twentieth century, super-computers like Deep Thought, and its successors Deep Blue and Watson, began to be described as "intelligent." But very few writers imagined these early examples of AI as animate beings possessing autonomous minds. Indeed, one of Watson's creators has explained that in trial versions of Watson playing Jeopardy, Watson would simply read out the question to an answer with no cues to the audience as to how it derived its answer. As a result, viewers were not very impressed. They thought Watson was just a huge databank of trivia. No one perceived it as thinking. So Watson's creators decided to have the computer show three potential correct answers and then state its conclusion about which one had the highest probability of being correct. This presentation was much more effective in demonstrating how Watson was not a mere storehouse of information but an information-processing machine that made reasoned calculations to determine its answer--something much closer to "thinking."

### Anima (Pam)
Ever since Ada Lovelace realized in 1843 that machines could act on things other than numbers, as long as those things could be represented by numbers, the ability of machines to succeed at tasks that had been the purview of humans has increased. This ability of machines to think (and think well--recent AIs have defeated the world Go champion [Go is a game that requires more "intuition" than chess] and poker professionals in Texas Hold 'em [Texas Hold 'em is a game that requires the ability to bluff] can strike people as both fascinating and unsettling. Why unsettling? Our argument is that, in Aristotelian terms, AI possesses the ineffable quality of anima (Pam say smart things about Aristotle here), but AI is embodied in ways unlike other animate beings. (While it is not quite accurate to speak of "substrate independence," as many in the AI world do, it is the case that the intelligence of AI relates differently to material bodies than do the animae of plants, animals, and humans. Computer algorithms need to run on hardware and operating systems, but can be downloaded and run on very different systems and hardware.) Descartes's mind/body dualism is, in part, a critique of Aristotelian categories of animae (different kinds of "souls" that impart "animation" to different kinds of creatures). And yet, despite philosophical critiques of Aristotle and Descartes, humans in the West tend to understand themselves as composed of mind and body, and tend to think of minds and bodies relating to each other roughly as Aristotle conceived of animae being embodied. Thus, the presence of an? anima with a different relationship to materiality can occasion feelings of the uncanny.

### Uncanny (Ted)
We use the term "uncanny" in the same fairly technical sense that the philosopher Franz Rosenzweig does when he claims that Jews cause a feeling of "uncanniness": a community wrenched from its homeland (*Heimat*) and present, as a community, in the home (*Heim*) of others, they provoke a feeling of uncanniness (*Unheimlichkeit*). (See Leora Batniztky, *Idoloatry and Representation: The Philosophy of Franz Rosenzweig Reconsidered*, esp. pp. 90-94.) We argue that the presence of the kind of animation we associate with minds that is dis-located (not in the *Heimat* with which we are "at home") is uncanny (*Unheimlich*). (We are not the first to note this--robotics engineers talk about the "uncanny valley".) John Seabrook, in the October 14 issue of the *New Yorker*, describes his feeling of using a machine in the form of a natural language processor (NLP) to that has the ability to complete sentences and paragraphs of the very article he is writing:
>The skin prickled on the back of my neck, an involuntary reaction to what roboticists call the “uncanny valley”—the space between flesh and blood and a too-human machine. . . . It was . . . disconcerting how frequently the A.I. was able to accurately predict my intentions, often when I was in midsentence, or even earlier. Sometimes the machine seemed to have a better idea than I did.

 We will not have the space to argue, but we do believe, that just as Rosenzweig argues that Christianity need the Jewish judgment of Christian incompleteness, so AI can raise important questions about what makes humans human, and about the hubristic place of humans in the universe that humans typically claim for themselves.

### Walking the talk (probably delete)
The argument unfolds in two stages. In addition to the familiar academic modes of research and interpretation of text, we deployed machine-learning methods as an experiment in using digital resources that are commonly regarded as simple forms of AI technology. Specifically, we used topic-modeling to analyze selected twentieth-century philosophical articles to test whether mind-body dualism is as stable and persistent an idea as we hypothesize. The models we used are rudimentary, and they serve more as illustrative instruments than conclusive ones. (We realize that this is not really an adequate way of demonstrating pervasive cultural mind/body assumptions; and it does not demonstrate that blurring mind/body distinctions feels uncanny to people. Possible future strategies include scraping Reddit chat rooms or Wikipedia or other large pools of data to ascertain prevailing attitudes towards minds and embodiedness outside the academy, and performing sentiment analysis on the literature of Spinoza's contemporaries to ascertain if part of the negative reaction to him can be characterized as the uncanniness of his arguments about monistic substance.)

Second, we hope to demonstrate the uncanniness of AI  by using the Generative Pre-Training Language Model developed by OpenAi (GPT2). GPT2 has been described as a form of language processing capable of finishing your sentences for you. One reviewer offers this  simple description of GPT2: "If you can predict the next word in a sentence, you can predict the word after that, and the next one after that, and pretty soon you have… a lot of words. And if your language modeling is good enough, these words will form meaningful sentences, and the sentences will form coherent paragraphs, and these paragraphs will form, well, just about anything you want." For example, the AI could produce the kinds of paragraphs in essays about the mind/body problem that we normally assume would be produced by a human scholar.
